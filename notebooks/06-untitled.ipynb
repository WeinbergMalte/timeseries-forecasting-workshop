{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "276b8768",
   "metadata": {},
   "source": [
    "### Time Series Workshop \n",
    "# 6. Online Retail: Forecasting Challenge Sample Solution\n",
    "\n",
    "Eh, this is a sample solution for the previous challenge. \n",
    "\n",
    "You were'nt supposed to see this. I didn't think anybody would open a notebook with the most uninteresting file name imaginable. Ah, whatever. &#x1F937;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from timeseries.data import load_retail\n",
    "from timeseries.utils import print_metrics\n",
    "\n",
    "DATA_DIR = Path(\"..\") / Path(\"data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0b20482",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d9a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"sales\"\n",
    "SPLIT_DATE = \"2011-09-30\"\n",
    "FILE_PATH = DATA_DIR / \"online_retail.csv\"\n",
    "\n",
    "df_in = load_retail(FILE_PATH)\n",
    "df_in.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ed895de",
   "metadata": {},
   "source": [
    "## Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_in.copy()\n",
    "\n",
    "_ = df.plot(figsize=[15, 4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a46e1b5",
   "metadata": {},
   "source": [
    "- Looks pretty benign, no missing values \n",
    "- Yearly seasonality pattern clearly visible!\n",
    "- Strong trend upwards!\n",
    "- The econmoic crisis in 2008 is clearly visible in the data as a cusp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1904787e",
   "metadata": {},
   "source": [
    " # Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q05(x):\n",
    "    return x.quantile(0.05)\n",
    "\n",
    "\n",
    "def q95(x):\n",
    "    return x.quantile(0.95)\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(figsize=(6, 4))\n",
    "df_season = df[[TARGET_COL]].copy()\n",
    "\n",
    "# Group by hour of the day and compute mean and 90% confidence interval\n",
    "df_season[\"m\"] = df_season.index.month\n",
    "df_time_season = df_season.groupby(\"m\")[[TARGET_COL]].agg([\"mean\", q05, q95])\n",
    "\n",
    "# Plot mean values\n",
    "ax.plot(df_time_season[TARGET_COL][\"mean\"], label=TARGET_COL, linewidth=2)\n",
    "\n",
    "# Plot confidence intervals\n",
    "ax.fill_between(\n",
    "    df_time_season.index,\n",
    "    df_time_season[TARGET_COL][\"q05\"],\n",
    "    df_time_season[TARGET_COL][\"q95\"],\n",
    "    alpha=0.2,\n",
    "    label=\"90% CI\",\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.set_xlim((1, 12))\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5aee981",
   "metadata": {},
   "source": [
    "- Seasonality analysis by grouping data is not helpful here, due to the strong trend!\n",
    "- We can use the `seasonal_decompose` function from `statsmodels` to decompose the time series into trend, seasonality and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "result = seasonal_decompose(df[TARGET_COL], model='additive')\n",
    "fig = result.plot()\n",
    "_ = fig.set_size_inches(15, 12)\n",
    "_ = plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca9a71c8",
   "metadata": {},
   "source": [
    "Looks good to me! \n",
    "- Strong trend\n",
    "- Yearly seasonality\n",
    "- Residuals are pretty random, but with a slight upwards trend\n",
    "\n",
    "I'll build a simple model out of this!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2427e76",
   "metadata": {},
   "source": [
    "## Build instructive model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0f62469",
   "metadata": {},
   "source": [
    "### 1. Train-test split\n",
    "- Before using the seasonality pattern and trend we got form the decomposition, we need to split off the test set as to not fall prey to look-ahead bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ffc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[df.index < SPLIT_DATE].copy()\n",
    "df_test = df.loc[df.index >= SPLIT_DATE].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = seasonal_decompose(df_train[TARGET_COL], model='additive')\n",
    "fig = result.plot()\n",
    "_ = fig.set_size_inches(15, 12)\n",
    "_ = plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e024c891",
   "metadata": {},
   "source": [
    "- If we now only take the slope of the trend and the seasonality pattern, we might already get a pretty good forecast\n",
    "- Let's extract the seasonality first\n",
    "\n",
    "Note: This is super manual stuff that's mainly meant to be instructive. In a real-world scenario, one would probably use a more sophisticated/easy to deal with model.\n",
    "\n",
    "First, we'll extract the seasonality (mapped to the month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df31cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_season = pd.DataFrame(result.seasonal)\n",
    "seasonality = df_season.groupby(df_season.index.month)[\"seasonal\"].mean().to_dict()\n",
    "\n",
    "_ , ax = plt.subplots(figsize=(5, 3))\n",
    "_ = ax.plot(seasonality.keys(), seasonality.values(), marker=\".\")\n",
    "_ = ax.set_xlabel(\"Month\")\n",
    "_ = ax.set_ylabel(\"Seasonality\")\n",
    "_ = ax.grid(linestyle=\":\")\n",
    "_ = plt.tight_layout()\n",
    "seasonality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4aa19fce",
   "metadata": {},
   "source": [
    "This looks ok-ish. Strong yearly seasonality. \n",
    "\n",
    "We'll use the dictionary for our super weird estimator!\n",
    "\n",
    "Next, we'll create train- and test sets. Not that here, the train set just includes the extracted trend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "trends = result.trend.dropna().copy()[\"2009-01-01\":]\n",
    "df_trainf = pd.DataFrame(index = trends.index)\n",
    "df_trainf[\"sales\"] = trends.values\n",
    "df_trainf[\"nmonth\"] = df_trainf.index.month\n",
    "df_trainf[\"n\"] = range(len(df_trainf))\n",
    "df_testf = df_test.copy()\n",
    "df_testf[\"nmonth\"] = df_testf.index.month\n",
    "df_testf[\"n\"] = range(len(df_trainf), len(df_trainf) + len(df_testf))\n",
    "\n",
    "X_trainf = df_trainf[[\"nmonth\", \"n\"]]\n",
    "y_trainf = df_trainf[TARGET_COL]\n",
    "X_testf = df_testf[[\"nmonth\", \"n\"]]\n",
    "y_testf = df_testf[TARGET_COL]\n",
    "\n",
    "df_trainf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7610737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testf.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6cfcab71",
   "metadata": {},
   "source": [
    "Let's build a weird little estimator that does the final steps for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45133830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "class MyFunnyTrendEstimator(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Weird little estimator that fits a trend and adds some seasonality mapping in predict\n",
    "    \n",
    "    :param seasonality_map: dict mapping month to seasonality\n",
    "    \"\"\"\n",
    "    def __init__(self, seasonality_map: dict[int, float]):\n",
    "        self.seasonality_map = seasonality_map\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.regressor = LinearRegression().fit(X[[\"n\"]], y)\n",
    "        self.coef = self.regressor.coef_[0]\n",
    "        self.intercept = self.regressor.intercept_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (\n",
    "            self.intercept + X[\"n\"] * self.coef + X[\"nmonth\"].map(self.seasonality_map)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a312a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyFunnyTrendEstimator(seasonality_map=seasonality)\n",
    "model.fit(X_trainf, y_trainf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5158d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_testf)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(10, 4))\n",
    "_ = df_train.plot(ax=ax)\n",
    "_ = df_test.plot(ax=ax)\n",
    "_ = y_pred.plot(ax=ax)\n",
    "_ = ax.legend([\"train\", \"test\", \"pred\"])\n",
    "_ = plt.tight_layout()\n",
    "\n",
    "print_metrics(y_testf, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5339559",
   "metadata": {},
   "source": [
    "Not too bad for this rather peculiar approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b63e735e",
   "metadata": {},
   "source": [
    "## Side Note: Autocorrelation!\n",
    "By the way, there's a different/better way to get an insight into seasonalities apart from this cumbersome stuff above!\n",
    "\n",
    "For this, we'll again need to de-trend the data first. We can do this by subtracting the trend we got from the decomposition but let's try a different trend calculation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ffc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "df[\"trend\"] = lowess(endog=df[\"sales\"], exog=np.arange(0, len(df)), frac=0.1)[:, 1]\n",
    "df[\"detrended_sales\"] = df[\"sales\"] - df[\"trend\"]\n",
    "\n",
    "_, axs = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "_ = axs[0].plot(df[\"sales\"], label=\"sales\")\n",
    "_ = axs[0].plot(df[\"trend\"], label=\"trend\")\n",
    "_ = axs[1].plot(df[\"detrended_sales\"], label=\"de-trended sales\")\n",
    "for ax in axs:\n",
    "    ax.grid(linestyle=\":\")\n",
    "    ax.legend()\n",
    "_ = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "_, axs = plt.subplots(2,1,figsize=(6, 6), sharex=True)\n",
    "_ = plot_acf(x=df[\"sales\"], lags=50, ax=axs[0])\n",
    "_ = axs[0].set_ylim((-1.1,1.1))\n",
    "_ = axs[0].set_title(\"\")\n",
    "_ = plot_acf(x=df[\"sales\"]- df[\"trend\"], lags=50, ax=axs[1])\n",
    "_ = axs[1].set_ylim((-1.1,1.1))\n",
    "_ = axs[1].set_xlabel(\"Lag\")\n",
    "\n",
    "for ax in axs:\n",
    "    _ = ax.set_title(\"\")\n",
    "    _ = ax.grid(linestyle=\":\")\n",
    "_ = plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c4e929a",
   "metadata": {},
   "source": [
    "And we finally have a very clear and significant seasonality pattern. Even some significant anticorrelations, apparently.\n",
    "\n",
    "But back to the problem at hand. Let's find an even better way to predict these sales!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcfb03cc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## The Cheat: Facebook Prophet!\n",
    "What's that? You ask. &#x1F914; Let's find out with ChatGPT!\n",
    "\n",
    "**Prompt:** \n",
    "\n",
    "Hi ChatGPT, can you write me a short markdown text explaining how Facebook prophet works? And please use some LaTeX expressions!\n",
    "\n",
    "**Response:**\n",
    "\n",
    "Certainly! Facebook Prophet is a time series forecasting model that decomposes the data into several components, including a trend component, a seasonal component, and a residual component. The additive composition of these components can be expressed as:\n",
    "\n",
    "\\begin{equation}\n",
    "y(t) = g(t) + s(t) + h(t) + \\epsilon_t\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "\n",
    "- $y(t)$ is the observed time series at time $t$\n",
    "- $g(t)$ is the trend component, which models the non-periodic changes in the time series over time\n",
    "- $s(t)$ is the seasonal component, which models the periodic changes in the time series over time\n",
    "- $h(t)$ is the holiday component, which models the effects of holidays and other events that occur irregularly over time\n",
    "- $\\epsilon_t$ is the residual component, which represents the random fluctuations in the time series that are not explained by the other components.\n",
    "\n",
    "\n",
    "Great! Thanks massive, uncanny language model that's on the verge of making my job obsolete! &#x1F9D0;\n",
    " \n",
    "### A word of caution  for Mac useres. &#x1F34F;\n",
    "- Prophet still is notoriously finnicky to set up on Apple M1 and M2 machines. \n",
    "- We didn't get it to run and didn't bother a lot. \n",
    "- So, look out for obscure errors when running the following code locally.\n",
    "\n",
    "Moving on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bfd323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet demands a certain naming of data frame columns:\n",
    "df_prophet = df.reset_index().rename(columns={\"month\": \"ds\", \"sales\": \"y\"})\n",
    "df_prophet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072ec052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "df_train = df_prophet.loc[df_prophet.ds < SPLIT_DATE].copy()\n",
    "df_test = df_prophet.loc[df_prophet.ds >= SPLIT_DATE].copy()\n",
    "\n",
    "m = Prophet()\n",
    "_ = m.fit(df_prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15806dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample = m.predict(df_train[[\"ds\"]])\n",
    "forecast = m.predict(df_test[[\"ds\"]])\n",
    "forecast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e7b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(8, 5))\n",
    "_ = m.plot(in_sample, ax=ax)\n",
    "_ = m.plot(forecast, ax=ax)\n",
    "_ = ax.axvline(pd.to_datetime(SPLIT_DATE), color=\"darkred\", linestyle=\"--\")\n",
    "_ = ax.set_xlabel(\"Date\")\n",
    "_ = ax.set_ylabel(\"Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d62957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can look at the resulting components of the model:\n",
    "_ = m.plot_components(in_sample, figsize=(7,4))\n",
    "_ = m.plot_components(forecast, figsize=(7,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66918db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(df_test[\"y\"], forecast[\"yhat\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c232abfd",
   "metadata": {},
   "source": [
    "## Why is this cheating a little bit? &#x1F92F;\n",
    "- Well, if you take a look at the data source URL it turns out to be a toy example **from the Prophet package**! \n",
    "- Such toy examples necessarily perform really well and are a bit uncritical to potential weaknesses of the model.\n",
    "\n",
    "## Why this is better than it looks? &#x1F632;\n",
    "- So far, we have limited ourselves to single-step forecasts. Only forecast one hour, one day, one month or so into the future.\n",
    "- Prophet does the whole thing: It produces a multi-horizon forecast without having seen the test data!! \n",
    "\n",
    "Note that also our super weird instructive estimator above did this, but it was a bit more cumbersome to set up.\n",
    "\n",
    "Let's dive into multi-step ahead forecasts in the next notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ab0208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce109e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
