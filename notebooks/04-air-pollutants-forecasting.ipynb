{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "276b8768",
   "metadata": {},
   "source": [
    "### Time Series Workshop \n",
    "# 4. Air Pollutants &#x1F525;: Forecasting\n",
    "\n",
    "In this notebook, we will use the preprocessed data from the feature engineering notebook and, finally, perform some forecasting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from timeseries.data import load_air_quality\n",
    "from timeseries.utils import print_metrics\n",
    "from sklearn.linear_model import Lasso\n",
    "from feature_engine.creation import CyclicalFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from timeseries import preprocessing as pp\n",
    "from sklearn.preprocessing import FunctionTransformer as ftrf\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"..\") / Path(\"data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0b20482",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d5a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = DATA_DIR / \"air_quality_processed.csv\"\n",
    "\n",
    "variables = [\"co_sensor\", \"humidity\"]\n",
    "\n",
    "df_in = pd.read_csv(\n",
    "    FILE_PATH,\n",
    "    parse_dates=[\"date_time\"],\n",
    "    index_col=[\"date_time\"],\n",
    ")\n",
    "df_in.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc8574a9",
   "metadata": {},
   "source": [
    "# Train-test split\n",
    "\n",
    "* We will train the model on a certain portion of the data and leave another part out to evaluate the model.\n",
    "\n",
    "* Contrary to regular machine learning problems, it is neccessary to strictly split on time in order to avoid leakage. \n",
    "\n",
    "* We will roughly use the first 90% of the data for training and the remaining 10% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DATE = \"2005-02-01\"\n",
    "TARGET_COL = \"co_sensor\"\n",
    "\n",
    "X_train = df_in[df_in.index <= SPLIT_DATE]\n",
    "X_test = df_in[df_in.index > SPLIT_DATE]\n",
    "\n",
    "y_train = X_train.pop(TARGET_COL)\n",
    "y_test = X_test.pop(TARGET_COL)\n",
    "\n",
    "train_ratio = len(y_train) / len(df_in)\n",
    "test_ratio = len(y_test) / len(df_in)\n",
    "\n",
    "print(f\"Train vs. test ratios: {train_ratio:.2%} vs. {test_ratio:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = pd.DataFrame(\n",
    "    index=pd.date_range(y_train.index.min(), y_train.index.max(), freq=\"1H\")\n",
    ")\n",
    "test_range = pd.DataFrame(\n",
    "    index=pd.date_range(y_test.index.min(), y_test.index.max(), freq=\"1H\")\n",
    ")\n",
    "\n",
    "y_train_plt = train_range.merge(y_train, left_index=True, right_index=True, how=\"left\")\n",
    "y_test_plt = test_range.merge(y_test, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "_, ax = plt.subplots(figsize=(15, 3))\n",
    "_ = ax.plot(y_train_plt, label=\"train\")\n",
    "_ = ax.plot(y_test_plt, label=\"test\")\n",
    "_ = plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1299a070",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOREST_FEATURES = [\n",
    "    \"month\",\n",
    "    \"week\",\n",
    "    \"day\",\n",
    "    \"day_of_week\",\n",
    "    \"hour\",\n",
    "    \"is_weekend\",\n",
    "    \"co_sensor_lag_1\",\n",
    "    \"co_sensor_lag_2\",\n",
    "    \"co_sensor_lag_3\",\n",
    "    \"co_sensor_lag_24\",\n",
    "    \"humidity_lag_1\",\n",
    "    \"humidity_lag_2\",\n",
    "    \"humidity_lag_3\",\n",
    "    \"humidity_lag_24\",\n",
    "    \"co_sensor_win_mean\",\n",
    "    \"co_sensor_win_min\",\n",
    "    \"co_sensor_win_max\",\n",
    "    \"co_sensor_win_std\",\n",
    "    \"humidity_win_mean\",\n",
    "    \"humidity_win_min\",\n",
    "    \"humidity_win_max\",\n",
    "    \"humidity_win_std\",\n",
    "]\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    random_state=0,\n",
    ")\n",
    "rf_model.fit(X_train[FOREST_FEATURES], y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test[FOREST_FEATURES])\n",
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_importances = pd.Series(rf_model.feature_importances_, index=FOREST_FEATURES)\n",
    "_ = rf_importances.plot.barh(figsize=(7, 5))\n",
    "_ = plt.xlabel(\"Feature Importance\")\n",
    "_ = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d95837",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_plt = test_range.merge(\n",
    "    pd.Series(y_pred, index=y_test.index, name=\"pred\"),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "_, ax = plt.subplots(figsize=(15, 3))\n",
    "_ = ax.plot(y_test_plt, label=\"test\")\n",
    "_ = ax.plot(y_pred_plt, label=\"pred\")\n",
    "_ = plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58bcce60",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4695d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINEAR_FEATURES = [\n",
    "    \"is_weekend\",\n",
    "    \"co_sensor_lag_1\",\n",
    "    \"co_sensor_lag_2\",\n",
    "    \"co_sensor_lag_3\",\n",
    "    \"co_sensor_lag_24\",\n",
    "    \"humidity_lag_1\",\n",
    "    \"humidity_lag_2\",\n",
    "    \"humidity_lag_3\",\n",
    "    \"humidity_lag_24\",\n",
    "    \"co_sensor_win_mean\",\n",
    "    \"co_sensor_win_min\",\n",
    "    \"co_sensor_win_max\",\n",
    "    \"co_sensor_win_std\",\n",
    "    \"humidity_win_mean\",\n",
    "    \"humidity_win_min\",\n",
    "    \"humidity_win_max\",\n",
    "    \"humidity_win_std\",\n",
    "    \"month_sin\",\n",
    "    \"month_cos\",\n",
    "    \"hour_sin\",\n",
    "    \"hour_cos\",\n",
    "]\n",
    "\n",
    "linear_model = Lasso(alpha=2, random_state=0)\n",
    "linear_model.fit(X_train[LINEAR_FEATURES], y_train)\n",
    "\n",
    "y_pred = linear_model.predict(X_test[LINEAR_FEATURES])\n",
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feee7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.Series(np.abs(linear_model.coef_), index=LINEAR_FEATURES)\n",
    "_ = coefs.plot.barh(figsize=(7, 5))\n",
    "_ = plt.xlabel(\"Feature Importance\")\n",
    "_ = plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ca5810",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_plt = test_range.merge(\n",
    "    pd.Series(y_pred, index=y_test.index, name=\"pred\"),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "_, ax = plt.subplots(figsize=(15, 3))\n",
    "_ = ax.plot(y_test_plt, label=\"test\")\n",
    "_ = ax.plot(y_pred_plt, label=\"pred\")\n",
    "_ = plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4fc2051",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "This endless stream of notebook cells doesn't exactly correspond to the usual best practices.\n",
    "\n",
    "Here's an example of the whole thing put together in a single cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd3a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params:\n",
    "FILE_PATH = DATA_DIR / \"air_quality.csv\"\n",
    "SPLIT_DATE = \"2005-02-01\"\n",
    "INPUT_COLS = [\"co_sensor\", \"humidity\"]\n",
    "CYCLIC_COLS = [\"month\", \"hour\"]\n",
    "TARGET_COL = \"co_sensor\"\n",
    "FEATURE_COLS = [\n",
    "    TARGET_COL,\n",
    "    \"is_weekend\",\n",
    "    \"co_sensor_lag_1\",\n",
    "    \"co_sensor_lag_2\",\n",
    "    \"co_sensor_lag_3\",\n",
    "    \"co_sensor_lag_24\",\n",
    "    \"humidity_lag_1\",\n",
    "    \"humidity_lag_24\",\n",
    "    \"co_sensor_win_min\",\n",
    "    \"co_sensor_win_std\",\n",
    "    \"humidity_win_max\",\n",
    "    \"month_sin\",\n",
    "    \"month_cos\",\n",
    "    \"hour_sin\",\n",
    "    \"hour_cos\",\n",
    "]\n",
    "\n",
    "# Load original data:\n",
    "df_in = load_air_quality(FILE_PATH)[INPUT_COLS]\n",
    "df_in.head()\n",
    "\n",
    "# Define preprocessing pipeline:\n",
    "preprocessing_steps = [\n",
    "    (\"remove_negative_values\", ftrf(pp.remove_negative_values)),\n",
    "    (\"time_features\", ftrf(pp.time_features)),\n",
    "    (\n",
    "        \"lag_features\",\n",
    "        ftrf(pp.lag_features, kw_args={\"columns\": INPUT_COLS, \"lags\": [1, 2, 3, 24]}),\n",
    "    ),\n",
    "    (\"window_features\", ftrf(pp.window_features, kw_args={\"columns\": INPUT_COLS})),\n",
    "    (\n",
    "        \"cyclical_features\",\n",
    "        CyclicalFeatures(\n",
    "            variables=CYCLIC_COLS,\n",
    "            drop_original=False,\n",
    "        ),\n",
    "    ),\n",
    "    (\"select_cols\", ftrf(pp.select_columns, kw_args={\"columns\": FEATURE_COLS})),\n",
    "    (\"remove_na_values\", ftrf(pp.remove_na)),\n",
    "]\n",
    "preprocessing_pipe = Pipeline(preprocessing_steps)\n",
    "\n",
    "# Apply preprocessing pipeline:\n",
    "df_processed = preprocessing_pipe.fit_transform(df_in)\n",
    "\n",
    "# Train-test split:\n",
    "X_train = df_processed[df_processed.index <= SPLIT_DATE]\n",
    "X_test = df_processed[df_processed.index > SPLIT_DATE]\n",
    "y_train = X_train.pop(TARGET_COL)\n",
    "y_test = X_test.pop(TARGET_COL)\n",
    "\n",
    "# Fit simple model:\n",
    "linear_model = Lasso(alpha=5, random_state=0)\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict:\n",
    "y_pred = linear_model.predict(X_test)\n",
    "print_metrics(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "306f97f1",
   "metadata": {},
   "source": [
    "Now this looks pretty amazing and all. It's just a one-hour forecast, though. Anyways, amazing! &#x1F973;\n",
    "\n",
    "But what should we have done first?\n",
    "\n",
    "#### Did we forget something? &#x1F6A8;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3760c7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac9ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b0a6198",
   "metadata": {},
   "source": [
    "## Post Scriptum: Refactored feature engineering\n",
    "- The code above is quite messy. Let's clean it up a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f688901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.creation import CyclicalFeatures\n",
    "from feature_engine.datetime import DatetimeFeatures\n",
    "from feature_engine.imputation import DropMissingData\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.timeseries.forecasting import (\n",
    "    LagFeatures,\n",
    "    WindowFeatures,\n",
    ")\n",
    "\n",
    "# Date feature transformer:\n",
    "datetime_features = DatetimeFeatures(\n",
    "    variables=\"index\",\n",
    "    features_to_extract=[\n",
    "        \"month\",\n",
    "        \"week\",\n",
    "        \"day_of_week\",\n",
    "        \"day_of_month\",\n",
    "        \"hour\",\n",
    "        \"weekend\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Lag feature transformer:\n",
    "lag_features = LagFeatures(\n",
    "    variables=variables, freq=[\"1H\", \"24H\"], missing_values=\"ignore\"\n",
    ")\n",
    "\n",
    "# Window feature transformer:\n",
    "window_features = WindowFeatures(\n",
    "    variables=variables,\n",
    "    window=\"3H\",\n",
    "    freq=\"1H\",\n",
    "    missing_values=\"ignore\",\n",
    "    functions=[\"mean\", \"min\", \"max\", \"std\"],\n",
    ")\n",
    "\n",
    "# Cyclical feature transformer (this one we already know!):\n",
    "cyclic_features = CyclicalFeatures(variables=[\"month\", \"hour\"], drop_original=False)\n",
    "\n",
    "# Drop missing data transformer:\n",
    "dropnas = DropMissingData()\n",
    "\n",
    "# Drop features transformer (to avoid look-ahead bias):\n",
    "drop_features = DropFeatures(features_to_drop=variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"datetime_features\", datetime_features),\n",
    "        (\"lag_features\", lag_features),\n",
    "        (\"window_features\", window_features),\n",
    "        (\"cyclic_features\", cyclic_features),\n",
    "        (\"dropnas\", dropnas),\n",
    "        (\"drop_features\", drop_features),\n",
    "    ]\n",
    ")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5d63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_in.copy()\n",
    "df_processed = pipe.fit_transform(df)\n",
    "df_processed.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c7b7f96",
   "metadata": {},
   "source": [
    "Ah, way better and not too cluttered. &#x1F9D8;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abb3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "df_train = df[df.index < SPLIT_DATE]\n",
    "df_test = df[df.index >= SPLIT_DATE]\n",
    "\n",
    "X_train = df_train.copy()\n",
    "X_test = df_test.copy()\n",
    "\n",
    "y_train = df_train[TARGET_COL]\n",
    "y_test = df_test[TARGET_COL]\n",
    "\n",
    "# Preprocessing:\n",
    "X_train_t = pipe.fit_transform(X_train)\n",
    "X_test_t = pipe.transform(X_test)\n",
    "\n",
    "y_train_t = y_train.loc[X_train_t.index]\n",
    "y_test_t = y_test.loc[X_test_t.index]\n",
    "\n",
    "# Fit simple model:\n",
    "linear_model = Lasso(alpha=1, random_state=0)\n",
    "linear_model.fit(X_train_t, y_train_t)\n",
    "\n",
    "# Predict:\n",
    "y_pred = linear_model.predict(X_test_t)\n",
    "print_metrics(y_test_t, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29f59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337de62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
